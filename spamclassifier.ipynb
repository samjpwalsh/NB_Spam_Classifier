{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classifier\n",
    "\n",
    "_Assignment for the University of Bath as part of MSc in Artificial Intelligence_ \n",
    "\n",
    "_Data Source: University of Bath department of Computer Science_\n",
    "\n",
    "\n",
    "## Data\n",
    "The training set consists of 1000 rows and 55 columns. Each row corresponds to one email message. The first column is the response variable and describes whether a message is spam `1` or ham `0`. The remaining 54 columns are features corresponding to 54 different keywords within the email message, including special characters (such as \":\", \"!\", and \"$\"). A feature has the value `1` if the keyword appears in the message and `0` otherwise. The messages are therefore represented using a binary bag-of-words model.  There is also a 500 row set of test data which is functionally identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam training data set: (1000, 55)\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 0 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\").astype(int)\n",
    "print(\"Shape of the spam training data set:\", training_spam.shape)\n",
    "print(training_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam testing data set: (500, 55)\n",
      "[[1 0 0 ... 1 1 1]\n",
      " [1 1 0 ... 1 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(int)\n",
    "print(\"Shape of the spam testing data set:\", testing_spam.shape)\n",
    "print(testing_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "The following code implements a naive bayes classifier from scratch without using external libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamClassifier:\n",
    "    def __init__(self, alpha):\n",
    "        self.log_class_priors = 0\n",
    "        self.theta = 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def train(self, data):\n",
    "        # Estimate log class priors:\n",
    "        response_variable = data[:, 0]\n",
    "        zero_count = 0\n",
    "        one_count = 0\n",
    "        for element in response_variable:\n",
    "            if element == 0:\n",
    "                zero_count += 1\n",
    "            elif element == 1:\n",
    "                one_count += 1\n",
    "            else:\n",
    "                raise ValueError(\"Non-binary response found\")\n",
    "        self.log_class_priors = np.log([zero_count / len(response_variable), one_count / len(response_variable)])\n",
    "        \n",
    "        # Estimate log conditional likelihoods:\n",
    "        theta = np.zeros([2, len(data[0])-1])\n",
    "        spam = np.array([])\n",
    "        ham = np.array([])\n",
    "        for row in data:\n",
    "            if row[0] == 0:\n",
    "                if len(ham) == 0:\n",
    "                    ham = row[1:]\n",
    "                else:\n",
    "                    ham = np.vstack((ham, row[1:]))\n",
    "            if row[0] == 1:\n",
    "                if len(spam) == 0:\n",
    "                    spam = row[1:]\n",
    "                else:\n",
    "                    spam = np.vstack((spam, row[1:]))\n",
    "        ham_totals = ham.sum(axis=0)\n",
    "        for i in range(len(theta[0])):\n",
    "            theta[0, i] = np.log((ham_totals[i] + self.alpha) / (ham_totals.sum() + len(ham) * self.alpha))\n",
    "        spam_totals = spam.sum(axis=0)\n",
    "        for i in range(len(theta[1])):\n",
    "            theta[1, i] = np.log((spam_totals[i] + self.alpha) / (spam_totals.sum() + len(spam) * self.alpha))\n",
    "        self.theta = theta\n",
    "        \n",
    "        \n",
    "    def predict(self, data):\n",
    "        class_predictions = np.zeros([len(data)])\n",
    "        for i in range(len(data)):\n",
    "            ham_likelihood = self.log_class_priors[0]\n",
    "            spam_likelihood = self.log_class_priors[1]\n",
    "            for j in range(len(data[i])):\n",
    "                ham_likelihood += data[i, j] * self.theta[0, j]\n",
    "                spam_likelihood += data[i, j] * self.theta[1, j]\n",
    "            if spam_likelihood > ham_likelihood:\n",
    "                class_predictions[i] = 1\n",
    "            else:\n",
    "                class_predictions[i] = 0\n",
    "\n",
    "        return class_predictions\n",
    "\n",
    "        \n",
    "def create_classifier(data, alpha):\n",
    "    classifier = SpamClassifier(alpha)\n",
    "    classifier.train(data)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation\n",
    "The k-fold cross validation code below is used to determine the optimal value of the smoothing parameter alpha. \n",
    "To optimise alpha I used k = 10 and the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation(data, k=10, min_alpha=0.01, max_alpha=1, alpha_step=0.01):\n",
    "    test_alpha = min_alpha\n",
    "    best_acc = 0\n",
    "    while test_alpha <= max_alpha:\n",
    "        n = 0\n",
    "        classifier = SpamClassifier(alpha=test_alpha)\n",
    "        accuracy_list = np.empty(k)\n",
    "        divided_data = np.split(data, k)\n",
    "        while n < k:\n",
    "            test_data = divided_data[n]\n",
    "            test_data_labels = test_data[:, 0]\n",
    "            test_data_minus_labels = test_data[:, 1:]\n",
    "            training_data = np.vstack(divided_data[:n] + divided_data[n+1:])\n",
    "            classifier.train(training_data)\n",
    "            prediction = classifier.predict(test_data_minus_labels)\n",
    "            accuracy = np.mean(np.equal(prediction, test_data_labels))\n",
    "            accuracy_list[n] = accuracy\n",
    "            n += 1\n",
    "        average_accuracy = np.average(accuracy_list)\n",
    "        if average_accuracy > best_acc:\n",
    "            best_acc = average_accuracy\n",
    "            best_alpha = test_alpha\n",
    "        test_alpha += alpha_step\n",
    "    return best_alpha, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 0.8899999999999999\n"
     ]
    }
   ],
   "source": [
    "best_alpha, best_acc = kfold_cross_validation(training_spam)\n",
    "print(best_alpha, best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896\n"
     ]
    }
   ],
   "source": [
    "classifier = create_classifier(training_spam, best_alpha)\n",
    "test_data_labels = testing_spam[:, 0]\n",
    "test_data_minus_labels = testing_spam[:, 1:]\n",
    "prediction = classifier.predict(test_data_minus_labels)\n",
    "accuracy = np.mean(np.equal(prediction, test_data_labels))\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
